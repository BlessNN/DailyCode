# -*- coding: utf-8 -*-
import scrapy
from ..items import HouseItem,CjHouseItem


class LianjiaSpider(scrapy.Spider):
    name = "lianjia"
    allowed_domains = ["fs.lianjia.com"]
 #   start_urls = ['http://fs.lianjia.com/chengjiao/']

    def start_requests(self):
        base_url = "http://fs.lianjia.com/chengjiao/pg{0}/"
        for p in range(1,10):
            url = base_url.format(p)
            print "adding start urls:"+ url
            yield scrapy.Request(url,dont_filter=True,callback=self.parse)


    def parse(self, response):
        lists = response.css('ul[class="listContent"] li')
        items = []
        for index,list in enumerate(lists):
            item = CjHouseItem()
            item['page_url'] = list.css("a[class='img']::attr(href)").extract()
            item['title'] = list.css("div[class='title'] a::text").extract()
            item['house_info'] = list.css("div[class='houseInfo']::text").extract()
            item['deal_data'] = list.css("div[class='dealDate']::text").extract()
            item['total_price'] = list.css("div[class='totalPrice'] span::text").extract()
            item['position_icon'] =  list.css("div[class='positionInfo']::text").extract()
            item['unit_price'] = list.css("div[class='unitPrice'] span::text").extract()
            item['deal_house_txt'] = list.css("div[class='dealHouseInfo'] span::text").extract()
            item['sell_flag'] = 1
            items.append(item)
#            print items
        return items

